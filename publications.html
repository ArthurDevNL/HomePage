<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Publications - Arthur Hemmer</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="stylesheet" href="css/custom.css">
</head>
<body class="bg-gray-100">
    <!-- Navigation -->
    <nav class="max-w-6xl mx-auto px-4 py-8">
        <div class="flex items-center space-x-6 text-lg justify-center">
            <a href="index.html" class="text-gray-600 hover:text-blue-600 transition duration-300">Home</a>
            <span class="text-gray-300">•</span>
            <a href="publications.html" class="text-blue-600 font-medium">Publications</a>
            <span class="text-gray-300">•</span>
            <a href="blog.html" class="text-gray-600 hover:text-blue-600 transition duration-300">Blog</a>
        </div>
    </nav>

    <!-- Main Content -->
    <div class="max-w-6xl mx-auto px-4 py-8">
        <div class="grid grid-cols-1 md:grid-cols-4 gap-8">
            <!-- Profile Section -->
            <div class="md:col-span-1">
                <div class="bg-white rounded-xl shadow-sm p-6">
                    <img src="images/profile.jpg" alt="Arthur Hemmer" class="rounded-lg shadow-md w-full max-w-[250px] mx-auto">
                    <div class="mt-6 space-y-2">
                        <p class="text-xl font-semibold text-gray-800">ML Research Engineer / PhD Candidate</p>
                        <p class="text-lg text-gray-600">Shift Technology and La Rochelle University</p>
                        <p class="text-lg text-gray-600">Paris, France</p>
                        <!-- Social Links -->
                        <div class="flex space-x-4 mt-4 pt-4 border-t border-gray-100">
                            <a href="https://www.linkedin.com/in/arthurhemmer/" class="text-gray-600 hover:text-blue-500">
                                <svg class="w-7 h-7" fill="currentColor" viewBox="0 0 24 24"><path d="M19 0h-14c-2.761 0-5 2.239-5 5v14c0 2.761 2.239 5 5 5h14c2.762 0 5-2.239 5-5v-14c0-2.761-2.238-5-5-5zm-11 19h-3v-11h3v11zm-1.5-12.268c-.966 0-1.75-.79-1.75-1.764s.784-1.764 1.75-1.764 1.75.79 1.75 1.764-.783 1.764-1.75 1.764zm13.5 12.268h-3v-5.604c0-3.368-4-3.113-4 0v5.604h-3v-11h3v1.765c1.396-2.586 7-2.777 7 2.476v6.759z"/></svg>
                            </a>
                            <a href="https://github.com/ArthurDevNL" class="text-gray-600 hover:text-gray-900">
                                <svg class="w-7 h-7" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/></svg>
                            </a>
                            <a href="https://stackoverflow.com/users/3229491/arthur" class="text-gray-600 hover:text-orange-500">
                                <svg class="w-7 h-7" fill="currentColor" viewBox="0 0 24 24"><path d="M15.725 0l-1.72 1.277 6.39 8.588 1.716-1.277L15.725 0zm-3.94 3.418l-1.369 1.644 8.225 6.85 1.369-1.644-8.225-6.85zm-3.15 4.465l-.905 1.94 9.702 4.517.904-1.94-9.701-4.517zm-1.85 4.86l-.44 2.093 10.473 2.201.44-2.092-10.473-2.203zM1.89 15.47V24h19.19v-8.53h-2.133v6.397H4.021v-6.396H1.89zm4.265 2.133v2.13h10.66v-2.13H6.154Z"/></svg>
                            </a>
                            <a href="https://scholar.google.com/citations?user=zpJowD8AAAAJ&hl=en&oi=ao" class="text-gray-600 hover:text-blue-600">
                                <svg class="w-7 h-7" fill="currentColor" viewBox="0 0 24 24"><path d="M5.242 13.769L0 9.5 12 0l12 9.5-5.242 4.269C17.548 11.249 14.978 9.5 12 9.5c-2.977 0-5.548 1.748-6.758 4.269zM12 10a7 7 0 1 0 0 14 7 7 0 0 0 0-14z"/></svg>
                            </a>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Publications Section -->
            <div class="md:col-span-3">
                <div class="bg-white rounded-xl shadow-sm p-8 space-y-8">
                    <h1 class="text-4xl font-bold text-gray-800 mb-8">Publications</h1>
                    
                    <!-- Publications List -->
                    <div class="space-y-10">
                        <!-- ConfBERT Publication -->
                        <div class="space-y-2">
                            <h2 class="text-2xl font-bold text-gray-800">Confidence-Aware Document OCR Error Detection</h2>
                            <p class="text-lg text-gray-700">Arthur Hemmer, Mickaël Coustaty, Nicola Bartolo, Jean-Marc Ogier</p>
                            <p class="text-base italic text-gray-500">Document Analysis Systems: 16th IAPR International Workshop, DAS 2024</p>
                            <p class="text-base text-gray-600 mt-3">
                                Optical Character Recognition (OCR) continues to face accuracy challenges that impact subsequent applications. To address these errors, we explore the utility of OCR confidence scores for enhancing post-OCR error detection. Our study involves analyzing the correlation between confidence scores and error rates across different OCR systems. We develop ConfBERT, a BERT-based model that incorporates OCR confidence scores into token embeddings and offers an optional pre-training phase for noise adjustment. Our experimental results demonstrate that integrating OCR confidence scores can enhance error detection capabilities. This work underscores the importance of OCR confidence scores in improving detection accuracy and reveals substantial disparities in performance between commercial and open-source OCR technologies.
                            </p>
                            <div class="flex space-x-4 mt-3">
                                <a href="https://link.springer.com/chapter/10.1007/978-3-031-70442-0_13" class="text-blue-500 hover:text-blue-700 text-base inline-flex items-center">
                                    <svg class="w-5 h-5 mr-1" fill="currentColor" viewBox="0 0 24 24">
                                        <path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8l-6-6zm4 18H6V4h7v5h5v11z"/>
                                    </svg>
                                    Springer
                                </a>
                                <a href="https://arxiv.org/abs/2409.04117" class="text-blue-500 hover:text-blue-700 text-base inline-flex items-center">
                                    <img src="images/arxiv-logomark-small.svg" class="w-5 h-5 mr-1 [filter:brightness(0)_saturate(100%)_invert(48%)_sepia(80%)_saturate(1000%)_hue-rotate(194deg)_brightness(101%)_contrast(101%)]" alt="arXiv logo"/>
                                    arXiv
                                </a>
                            </div>
                        </div>

                        <!-- Lazy-k Publication -->
                        <div class="space-y-2">
                            <h2 class="text-2xl font-bold text-gray-800">Lazy-k: Decoding for Constrained Information Extraction</h2>
                            <p class="text-lg text-gray-700">Arthur Hemmer, Mickaël Coustaty, Nicola Bartolo, Jérôme Brachat, Jean-Marc Ogier</p>
                            <p class="text-base italic text-gray-500">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, 2023</p>
                            <p class="text-base text-gray-600 mt-3">
                                We explore the possibility of improving probabilistic models in structured prediction. Specifically, we combine the models with constrained decoding approaches in the context of token classification for information extraction. The decoding methods search for constraint-satisfying label-assignments while maximizing the total probability. To do this, we evaluate several existing approaches, as well as propose a novel decoding method called Lazy-k. Our findings demonstrate that constrained decoding approaches can significantly improve the models' performances, especially when using smaller models. The Lazy-k approach allows for more flexibility between decoding time and accuracy.
                            </p>
                            <div class="flex space-x-4 mt-3">
                                <a href="https://aclanthology.org/2023.emnlp-main.416" class="text-blue-500 hover:text-blue-700 text-base inline-flex items-center">
                                    <svg class="w-5 h-5 mr-1" fill="currentColor" viewBox="0 0 24 24">
                                        <path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8l-6-6zm4 18H6V4h7v5h5v11z"/>
                                    </svg>
                                    ACL Anthology
                                </a>
                                <a href="https://arxiv.org/abs/2312.03367" class="text-blue-500 hover:text-blue-700 text-base inline-flex items-center">
                                    <img src="images/arxiv-logomark-small.svg" class="w-5 h-5 mr-1 [filter:brightness(0)_saturate(100%)_invert(48%)_sepia(80%)_saturate(1000%)_hue-rotate(194deg)_brightness(101%)_contrast(101%)]" alt="arXiv logo"/>
                                    arXiv
                                </a>
                                <a href="https://github.com/ArthurDevNL/lazyk" class="text-blue-500 hover:text-blue-700 text-base inline-flex items-center">
                                    <svg class="w-5 h-5 mr-1" fill="currentColor" viewBox="0 0 24 24">
                                        <path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/>
                                    </svg>
                                    Code
                                </a>
                            </div>
                        </div>

                        <!-- Denoising Complexity Publication -->
                        <div class="space-y-2">
                            <h2 class="text-2xl font-bold text-gray-800">Estimating Post-OCR Denoising Complexity on Numerical Texts</h2>
                            <p class="text-lg text-gray-700">Arthur Hemmer, Jérôme Brachat, Mickaël Coustaty, Jean-Marc Ogier</p>
                            <p class="text-base italic text-gray-500">Communications in Computer and Information Science, Volume 1863, 2023</p>
                            <p class="text-base text-gray-600 mt-3">
                                Post-OCR processing has significantly improved over the past few years. However, these have been primarily beneficial for texts consisting of natural, alphabetical words, as opposed to documents of numerical nature such as invoices, payslips, medical certificates, etc. To evaluate the OCR post-processing difficulty of these datasets, we propose a method to estimate the denoising complexity of a text and evaluate it on several datasets of varying nature, and show that texts of numerical nature have a significant disadvantage. We evaluate the estimated complexity ranking with respect to the error rates of modern-day denoising approaches to show the validity of our estimator.
                            </p>
                            <div class="flex space-x-4 mt-3">
                                <a href="https://link.springer.com/chapter/10.1007/978-3-031-42430-4_6" class="text-blue-500 hover:text-blue-700 text-base inline-flex items-center">
                                    <svg class="w-5 h-5 mr-1" fill="currentColor" viewBox="0 0 24 24">
                                        <path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8l-6-6zm4 18H6V4h7v5h5v11z"/>
                                    </svg>
                                    Springer
                                </a>
                                <a href="https://arxiv.org/abs/2307.01020" class="text-blue-500 hover:text-blue-700 text-base inline-flex items-center">
                                    <img src="images/arxiv-logomark-small.svg" class="w-5 h-5 mr-1 [filter:brightness(0)_saturate(100%)_invert(48%)_sepia(80%)_saturate(1000%)_hue-rotate(194deg)_brightness(101%)_contrast(101%)]" alt="arXiv logo"/>
                                    arXiv
                                </a>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</body>
</html> 